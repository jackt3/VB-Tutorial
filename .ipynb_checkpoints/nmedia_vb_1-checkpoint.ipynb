{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7ee3054",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b7b9b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual, GridspecLayout\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e73465b9",
   "metadata": {},
   "source": [
    "# Model Fitting\n",
    "\n",
    "Suppose you have obtained some data / observations and are now wondering what to do with them. If you suspect the data has a particular model, you can optimise the parameters of your model such that they are best explained by the data.\n",
    "\n",
    "The aim of this tutorial is to familiarise you with Bayesian model fitting. Like all good tutorials, we'll assume our data was generated from a Normal distribution. We'll then see\n",
    "\n",
    "Like all good tutorials, we'll assume the data was generated from a Normal distribution. Ultimately what we want to estimate here is the mean and the variance of the distribution from which we obtained our data.\n",
    "\n",
    "# Sample some data\n",
    "\n",
    "Below, we'll sample some data from a 1-dimensional Normal distribution and plot their histogram. Feel free to play with the value of the mean, $\\mu$, and the standard deviation, $\\sigma$, and see how this changes the data.\n",
    "\n",
    "Things to note/try:\n",
    "* For large values of $N$, you should see the typical bell-curve shape of the Normal distribution.\n",
    "* If you change $\\mu$, the centre of the data will move (i.e. the centre value on the $x$ axis will move).\n",
    "* If you increase $\\sigma$, the spread of the data will increase (i.e. the range on the $x$ axis will increase)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd6a974e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define some plotting functions\n",
    "colours = {\"ground_truth\": \"#4daf4a\",\n",
    "           \"empirical\": \"#f781bf\",\n",
    "           \"exact\": \"#377eb8\",\n",
    "           \"approx\": \"#ff7f00\"}\n",
    "linestyles = {\"ground_truth\": \"solid\",\n",
    "              \"empirical\": \"dashdot\",\n",
    "              \"exact\": \"dashed\",\n",
    "              \"approx\": \"dotted\"}\n",
    "\n",
    "def get_contours(x, mu, std):\n",
    "    return (1 / (std * np.sqrt(np.pi))) * np.exp(-0.5 * np.square((x - mu) / std))\n",
    "\n",
    "def plot_contours(ax, x1, y1, c1, l1, ls1, x2=None, y2=None, c2=None, l2=None, ls2=None):\n",
    "    ax.plot(x1, y1, color=c1, label=l1, linestyle=ls1)\n",
    "    if x2:\n",
    "        ax.plot(x2, y2, color=c2, label=l2, linestyle=ls2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed1a934e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_contours(change):\n",
    "    x = np.linspace(mu.value - 3*std.value, mu.value + 3*std.value, 1000)\n",
    "    data_contour = get_contours(x, mu.value, std.value)\n",
    "    emp_contour = get_contours(x, emp_mean, emp_std)\n",
    "    ax10.clear()\n",
    "    plot_contours(ax10, x, data_contour, colours[\"ground_truth\"], \"Ground Truth\", linestyles[\"ground_truth\"],\n",
    "                  x, emp_contour, colours[\"approx\"], \"Empirical\", linestyles[\"approx\"])\n",
    "\n",
    "emp_mean, emp_std = [np.mean(w.value), np.std(w.value)]\n",
    "display(w);\n",
    "\n",
    "fig10, ax10 = plt.subplots(num=10)\n",
    "x = np.linspace(mu.value - 3*std.value, mu.value + 3*std.value, 1000)\n",
    "data_contour = get_contours(x, mu.value, std.value)\n",
    "emp_contour = get_contours(x, emp_mean, emp_std)\n",
    "plot_contours(ax10, x, data_contour, colours[\"ground_truth\"], \"Ground Truth\", linestyles[\"ground_truth\"],\n",
    "              x, emp_contour, colours[\"approx\"], \"Empirical\", linestyles[\"approx\"])\n",
    "[w.children[n].observe(update_contours, 'value') for n in range(len(w.children))];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea7eea57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate empirical mean and standard deviation from our observations\n",
    "emp_mean, emp_std = [np.mean(w.value), np.std(w.value)]\n",
    "\n",
    "def plot_histograms(ax, mean1, std1, mean2, std2,\n",
    "                    label1=\"Empirical Approximation\", label2=\"Ground Truth\",\n",
    "                    c1=\"#377eb8\", c2=\"#4daf4a\", meanstd1=False):\n",
    "    ax.hist(np.random.normal(mean1, std1, [50000]), color=c1, alpha=0.3, bins=50, align='left', label=label1)\n",
    "    ax.axvline(mean1, color='k', linestyle='solid')\n",
    "    ax.hist(np.random.normal(mean2, std2, [50000]), color=c2, alpha=0.3, bins=50, align='left', label=label2)\n",
    "    ax.axvline(mean2, color='g', linestyle='solid')\n",
    "    ax.legend(loc='upper right');\n",
    "    if meanstd1:\n",
    "        ax.axvline(mean1-2*meanstd1, color='k', linestyle='--')\n",
    "        ax.axvline(mean1+2*meanstd1, color='k', linestyle='--')\n",
    "\n",
    "def update_empirical_histograms(change):\n",
    "    ax1.clear()\n",
    "    emp_mean, emp_std = [np.mean(w.value), np.std(w.value)]\n",
    "    plot_histograms(ax1, emp_mean, emp_std, mu.value, std.value)\n",
    "\n",
    "display(w);\n",
    "\n",
    "fig1, ax1 = plt.subplots(num=1)\n",
    "plot_histograms(ax1, emp_mean, emp_std, mu.value, std.value)\n",
    "[w.children[n].observe(update_empirical_histograms, 'value') for n in range(len(w.children))];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f93e8bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(N, mu, std):\n",
    "    w.value = np.random.normal(mu, std, [N])\n",
    "\n",
    "def display_data(ax, data):\n",
    "    ax.hist(w.value, bins=10, color='g', align='left')\n",
    "    plt.show()\n",
    "    \n",
    "def update_plot(change):\n",
    "    ax0.clear()\n",
    "    display_data(ax0, data=w.value)\n",
    "\n",
    "# set up figure\n",
    "fig0, ax0 = plt.subplots(num=0)\n",
    "\n",
    "# get our widgets\n",
    "N = widgets.IntSlider(value=50, min=5, max=500, step=5, description=\"N\", continuous_update=False)\n",
    "mu = widgets.IntSlider(value=0, min=-10, max=10, step=1, description=\"$\\mu$\", continuous_update=False)\n",
    "std = widgets.FloatSlider(value=1., min=0.1, max=10, step=0.1, description=\"$\\sigma$\", continuous_update=False)\n",
    "\n",
    "w = interactive(get_data, N=N, mu=mu, std=std);\n",
    "display(w);\n",
    "\n",
    "# display our data\n",
    "display_data(ax0, w.value);\n",
    "\n",
    "# watch for a change in our widgets. This is messy, is there a nicer way to do it?\n",
    "[w.children[n].observe(update_plot, 'value') for n in range(len(w.children))];"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d46f79a6",
   "metadata": {},
   "source": [
    "# Empirical Mean and Standard Deviation\n",
    "\n",
    "The first thing we might think to do is simply to take the mean and the standard deviation of our observations without trying to include prior knowledge about their values or estimate confidence in their values.\n",
    "\n",
    "Below, we draw lots of samples from the ground truth distribution, i.e. $\\mathcal{N} \\left( \\mu, \\sigma^2 \\right)$, and plot the ground truth histogram in green. This is overlaid on our learned distribution which is in gray.\n",
    "\n",
    "If you play around with the values of the parameters above and rerun the cell below you should notice:\n",
    "* Increasing the number of observations, $N$, drives our empirical approximation closer to the ground truth;\n",
    "* Similarly, deacreasing the standard deviation, $\\sigma$, of our distribution generally results in a better approximation;\n",
    "* If we have a small number of observations, $N$, and a large standard deviation, $\\sigma$, our empirical approximation can be quite poor!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "70d81f97",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'w' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-8968fc3f10e8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# calculate empirical mean and standard deviation from our observations\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0memp_mean\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0memp_std\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m def plot_histograms(ax, mean1, std1, mean2, std2,\n\u001b[0;32m      5\u001b[0m                     \u001b[0mlabel1\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"Empirical Approximation\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel2\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"Ground Truth\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'w' is not defined"
     ]
    }
   ],
   "source": [
    "# calculate empirical mean and standard deviation from our observations\n",
    "emp_mean, emp_std = [np.mean(w.value), np.std(w.value)]\n",
    "\n",
    "def plot_histograms(ax, mean1, std1, mean2, std2,\n",
    "                    label1=\"Empirical Approximation\", label2=\"Ground Truth\",\n",
    "                    c1=\"#377eb8\", c2=\"#4daf4a\", meanstd1=False):\n",
    "    ax.hist(np.random.normal(mean1, std1, [50000]), color=c1, alpha=0.3, bins=50, align='left', label=label1)\n",
    "    ax.axvline(mean1, color='k', linestyle='solid')\n",
    "    ax.hist(np.random.normal(mean2, std2, [50000]), color=c2, alpha=0.3, bins=50, align='left', label=label2)\n",
    "    ax.axvline(mean2, color='g', linestyle='solid')\n",
    "    ax.legend(loc='upper right');\n",
    "    if meanstd1:\n",
    "        ax.axvline(mean1-2*meanstd1, color='k', linestyle='--')\n",
    "        ax.axvline(mean1+2*meanstd1, color='k', linestyle='--')\n",
    "\n",
    "def update_empirical_histograms(change):\n",
    "    ax1.clear()\n",
    "    emp_mean, emp_std = [np.mean(w.value), np.std(w.value)]\n",
    "    plot_histograms(ax1, emp_mean, emp_std, mu.value, std.value)\n",
    "\n",
    "display(w);\n",
    "\n",
    "fig1, ax1 = plt.subplots(num=1)\n",
    "plot_histograms(ax1, emp_mean, emp_std, mu.value, std.value)\n",
    "[w.children[n].observe(update_empirical_histograms, 'value') for n in range(len(w.children))];"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f7acd8b",
   "metadata": {},
   "source": [
    "# Bayesian Inference\n",
    "\n",
    "Suppose we also want to express our confidence in our parameter estimates, i.e. how confident are we in our estimate of the mean, $\\mu$? The simple method above can't do this. It only gives us estimates of $\\mu$ and $\\sigma$. It also doesn't let us include prior knowledge about the ground truth distribution.\n",
    "\n",
    "If you aren't familiar with probability or feel like you could be doing with a refresher, don't worry! The aim of this section is to give you some intuition into the different parts of a Bayesian model, not to be able to reproduce the code below. You should play around with the values used in the model via the sliders and watch how this changes the solution. This will hopefully make you more comfortable when reading about methods using Bayesian models - these pop up very frequently in medical image analysis!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10ef13ec",
   "metadata": {},
   "source": [
    "## Set up our prior\n",
    "\n",
    "Bayesian inference allows us to include any prior information we have about the distribution which generated our observations. This can be very helpful in two situations in particular:\n",
    "* When we don't have many observations;\n",
    "* When our observations are very noisy.\n",
    "\n",
    "In the following model, we have 4 parameters. These are:\n",
    "* $m_0$ = Our prior knowledge of the mean;\n",
    "* $v_0$ = Our prior confidence in our prior mean;\n",
    "* $\\beta_0$ = Our prior on the mean of the variance;\n",
    "* $\\sigma_0$ = How confident we are in our prior on the variance.\n",
    "\n",
    "Our uncertainty about our prior's mean is shown by the dashed lines. These have been drawn at $m_0 \\pm2v_0$. The default setting of the prior where $v_0 = 1000$ reflects the fact that we are highly uncertain about our prior value on the mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e00218c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_prior(m0, v0, beta_mean0, beta_var0):\n",
    "    print(m0, v0, beta_mean0, beta_var0)\n",
    "\n",
    "def update_prior_histograms(change):\n",
    "    ax2.clear()\n",
    "    plot_histograms(ax2, m0.value, beta_mean0.value, mu.value, std.value,\n",
    "                    label1=\"Prior distribution\", label2=\"Data distribution\")#,\n",
    "#                     meanstd1=np.sqrt(v0.value*beta_mean0.value))\n",
    "    \n",
    "# create widgets for the prior values of our NormalGamma distribution\n",
    "m0 = widgets.IntSlider(value=0, min=-10, max=10, step=1, description=\"$m_0$\", continuous_update=False)\n",
    "v0 = widgets.IntSlider(value=1000, min=1, max=1000, step=1, description=\"$v_0$\", continuous_update=False)\n",
    "beta_mean0 = widgets.IntSlider(value=1, min=1, max=100, step=1, description=\"Beta mean\", continuous_update=False)\n",
    "beta_var0 = widgets.IntSlider(value=1000, min=1, max=1000, step=1, description=\"Beta var\", continuous_update=False)\n",
    "prior_widget = interactive(print_prior, m0=m0, v0=v0, beta_mean0=beta_mean0, beta_var0=beta_var0)\n",
    "\n",
    "fig2, ax2 = plt.subplots(num=2)\n",
    "plot_histograms(ax2, m0.value, beta_mean0.value, mu.value, std.value,\n",
    "                label1=\"Prior distribution\", label2=\"Data distribution\")#,\n",
    "#                 meanstd1=np.sqrt(v0.value*beta_mean0.value))\n",
    "\n",
    "grid = GridspecLayout(1, 2)\n",
    "grid[0, 0] = w\n",
    "grid[0, 1] = prior_widget\n",
    "display(grid);\n",
    "\n",
    "[w.children[n].observe(update_prior_histograms, 'value') for n in range(len(w.children))];\n",
    "[prior_widget.children[n].observe(update_prior_histograms, 'value') for n in range(len(prior_widget.children))];"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dffcaf9f",
   "metadata": {},
   "source": [
    "## Exact Solution\n",
    "\n",
    "In a lot of cases, inferring the posterior distribution of our parameters is an intractable problem. In the case we're considering here however, we can find the exact solution!\n",
    "\n",
    "We'll see later how we can still get reasonable approximations of the posterior in cases where our problem is intractable. Also, because we will have the exact solution, we can easily compare the approximated solution with the exact solution to see how good it is - handy!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1126c81d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_exact_histograms(change):\n",
    "    ax4.clear()\n",
    "    m, v, beta_mean, beta_var = exact_solution(w.value, m0.value, v0.value, beta_mean0.value, beta_var0.value)\n",
    "    plot_histograms(ax4, m, np.sqrt(1/beta_mean), mu.value, std.value,\n",
    "                    label1=\"Exact solution\", label2=\"Data distribution\")\n",
    "\n",
    "def exact_solution(data, m0, v0, beta_mean0, beta_var0):\n",
    "    # get number of observations\n",
    "    n = len(data)\n",
    "    \n",
    "    # convert prior parameters into form expected in update equations\n",
    "    l0 = 1 / v0\n",
    "    a0 = 1 / (beta_var0*beta_mean0)\n",
    "    b0 = 1 / (beta_var0*(beta_mean0**2))\n",
    "    \n",
    "    # get exact solution\n",
    "    xbar = np.mean(data)\n",
    "    s = np.mean(np.square(data-xbar))\n",
    "    m = (l0*m0 + n*xbar) / (l0 + n)\n",
    "    l = l0 + n\n",
    "    a = a0 + n/2\n",
    "    b = b0 + 0.5*n*(s + l0*((xbar-m0)**2)/(l0 + n))\n",
    "    \n",
    "    # convert parameters back to same form as in prior\n",
    "    v = 1 / l\n",
    "    beta_mean = a / b\n",
    "    beta_var = (a**2) / b\n",
    "    \n",
    "    return m, v, beta_mean, beta_var\n",
    "\n",
    "mE, vE, beta_meanE, beta_varE = exact_solution(w.value, m0.value, v0.value, beta_mean0.value, beta_var0.value)\n",
    "\n",
    "fig4, ax4 = plt.subplots(num=4)\n",
    "plot_histograms(ax4, mE, np.sqrt(1/beta_meanE), mu.value, std.value,\n",
    "                label1=\"Exact solution\", label2=\"Data distribution\")\n",
    "\n",
    "display(grid);\n",
    "\n",
    "[w.children[n].observe(update_exact_histograms, 'value') for n in range(len(w.children))];\n",
    "[prior_widget.children[n].observe(update_exact_histograms, 'value') for n in range(len(prior_widget.children))];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e6391da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_exact_histograms(change):\n",
    "    ax5.clear()\n",
    "    m, v, beta_mean, beta_var = exact_solution(w.value, m0.value, v0.value, beta_mean0.value, beta_var0.value)\n",
    "    plot_histograms(ax5, m, np.sqrt(1/beta_mean), mu.value, std.value,\n",
    "                    label1=\"Exact solution\", label2=\"Data distribution\")\n",
    "\n",
    "def exact_solution(data, m0, v0, beta_mean0, beta_var0):\n",
    "    # get number of observations\n",
    "    n = len(data)\n",
    "    \n",
    "    # convert prior parameters into form expected in update equations\n",
    "    l0 = 1 / v0\n",
    "    beta_var0 = 1/beta_var0\n",
    "    a0 = beta_var0 / beta_mean0\n",
    "    b0 = beta_var0 / (beta_mean0**2)\n",
    "    \n",
    "    # get exact solution\n",
    "    xbar = np.mean(data)\n",
    "    s = np.mean(np.square(data-xbar))\n",
    "    m = (l0*m0 + n*xbar) / (l0 + n)\n",
    "    l = l0 + n\n",
    "    a = a0 + n/2\n",
    "    b = b0 + 0.5*n*(s + l0*((xbar-m0)**2)/(l0 + n))\n",
    "    \n",
    "    # convert parameters back to same form as in prior\n",
    "    v = 1 / l\n",
    "    beta_mean = a / b\n",
    "    beta_var = (a**2) / b\n",
    "    \n",
    "    return m, v, beta_mean, beta_var\n",
    "\n",
    "mE, vE, beta_meanE, beta_varE = exact_solution(w.value, m0.value, v0.value, beta_mean0.value, beta_var0.value)\n",
    "\n",
    "fig5, ax5 = plt.subplots(num=5)\n",
    "plot_histograms(ax5, mE, np.sqrt(1/beta_meanE), mu.value, std.value,\n",
    "                label1=\"Exact solution\", label2=\"Data distribution\")\n",
    "\n",
    "display(grid);\n",
    "\n",
    "[w.children[n].observe(update_exact_histograms, 'value') for n in range(len(w.children))];\n",
    "[prior_widget.children[n].observe(update_exact_histograms, 'value') for n in range(len(prior_widget.children))];"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d99b870",
   "metadata": {},
   "source": [
    "# Variational Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc92e80e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_vb_histograms(change):\n",
    "    ax3.clear()\n",
    "    m, v, beta_mean, beta_var = vb_solution(w.value, m0.value, v0.value, beta_mean0.value, beta_var0.value)\n",
    "    plot_histograms(ax3, m, np.sqrt(1/beta_mean), mu.value, std.value,\n",
    "                    label1=\"Approximated distribution\", label2=\"Data distribution\")\n",
    "\n",
    "def vb_solution(data, m0, v0, beta_mean0, beta_var0, iterations=10):\n",
    "    N = len(data)\n",
    "    s1 = np.sum(data)\n",
    "    s2 = np.sum(np.square(data))\n",
    "    b0, c0 = (beta_var0/beta_mean0), (beta_mean0**2)/beta_var0\n",
    "    m, v, b, c = m0, v0, b0, c0\n",
    "    for i in range(iterations):\n",
    "        m = (m0 + v0*b*c*s1) / (1 + N*v0*b*c)\n",
    "        v = v0 / (1 + N*v0*b*c)\n",
    "        X = s2 - 2*s1*m + N*(m**2 + v)\n",
    "        b = 1 / (1/b0 + X/2)\n",
    "        c = N/2 + c0\n",
    "    beta_mean = b * c\n",
    "    beta_var = (b**2) * c\n",
    "    return m, v, beta_mean, beta_var\n",
    "\n",
    "mVB, vVB, beta_meanVB, beta_varVB = vb_solution(w.value, m0.value, v0.value, beta_mean0.value, beta_var0.value)\n",
    "\n",
    "fig3, ax3 = plt.subplots(num=3)\n",
    "plot_histograms(ax3, mVB, np.sqrt(1/beta_meanVB), mu.value, std.value,\n",
    "                label1=\"Approximated distribution\", label2=\"Data distribution\")\n",
    "\n",
    "display(grid);\n",
    "\n",
    "[w.children[n].observe(update_vb_histograms, 'value') for n in range(len(w.children))];\n",
    "[prior_widget.children[n].observe(update_vb_histograms, 'value') for n in range(len(prior_widget.children))];"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e9118a5",
   "metadata": {},
   "source": [
    "# Comparing our approximation to the exact solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "158baa89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_contour(x, mean, std):\n",
    "    return (1 / (std * np.sqrt(np.pi))) * np.exp(-0.5 * np.square((x - mean) / std))\n",
    "\n",
    "def plot_contours(ax):\n",
    "    meanE, standard_devE = [], []\n",
    "    meanVB, standard_devVB = [], []\n",
    "    # average over 100 runs\n",
    "    for i in range(100):\n",
    "        data = np.random.normal(mu.value, std.value, [N.value])\n",
    "\n",
    "        # get exact and VB solutions\n",
    "        mE, vE, beta_meanE, beta_varE = exact_solution(w.value, m0.value, v0.value, beta_mean0.value, beta_var0.value)\n",
    "        mVB, vVB, beta_meanVB, beta_varVB = vb_solution(w.value, m0.value, v0.value, beta_mean0.value, beta_var0.value)\n",
    "        stdE, stdVB = [1/np.sqrt(beta_mean) for beta_mean in (beta_meanE, beta_meanVB)]\n",
    "        \n",
    "        # append to list\n",
    "        meanE.append(mE)\n",
    "        standard_devE.append(stdE)\n",
    "        meanVB.append(mVB)\n",
    "        standard_devVB.append(stdVB)\n",
    "        \n",
    "    # take mean across all runs\n",
    "    mE, stdE = [np.mean(s) for s in (meanE, standard_devE)]\n",
    "    mVB, stdVB = [np.mean(s) for s in (meanVB, standard_devVB)]\n",
    "    \n",
    "    # get range of points on x-axis\n",
    "    x = np.linspace(mu.value-3*std.value, mu.value+3*std.value, 1000)\n",
    "    x = np.linspace(mE-3*stdE, mE+3*stdE, 1000)\n",
    "    \n",
    "    # get contours\n",
    "    yE = get_contour(x, mE, stdE)\n",
    "    yVB = get_contour(x, mVB, stdVB)\n",
    "    \n",
    "    # plot\n",
    "    ax.plot(x, yE, color='b', label='Exact solution')\n",
    "    ax.plot(x, yVB, color='b', ls='--', label='Approximate solution')\n",
    "    \n",
    "    ax.legend(loc='upper right')\n",
    "\n",
    "def update_contour_plot(change):\n",
    "    ax6.clear()\n",
    "    plot_contours(ax6)\n",
    "\n",
    "fig6, ax6 = plt.subplots(num=6)\n",
    "plot_contours(ax6)\n",
    "\n",
    "display(grid);\n",
    "\n",
    "[w.children[n].observe(update_contour_plot, 'value') for n in range(len(w.children))];\n",
    "[prior_widget.children[n].observe(update_contour_plot, 'value') for n in range(len(prior_widget.children))];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fba9a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_exact_solution(data, m0, v0, beta_mean0, beta_var0):\n",
    "    # get number of observations\n",
    "    n = len(data)\n",
    "    \n",
    "    # convert prior parameters into form expected in update equations\n",
    "    k0 = 1 / v0\n",
    "    a0 = (beta_mean0**2) / beta_var0\n",
    "    b0 = beta_mean0 / beta_var0\n",
    "    \n",
    "    # get exact solution\n",
    "    xbar = np.mean(data)\n",
    "    s = np.mean(np.square(data-xbar))\n",
    "    mN = (k0*m0 + n*xbar) / (k0 + n)\n",
    "    kN = k0 + n\n",
    "    aN = a0 + n/2\n",
    "    bN = b0 + 0.5*n*(s + k0*((xbar-m0)**2)/(k0 + n))\n",
    "    \n",
    "    # convert parameters back to same form as in prior\n",
    "    vN = 1 / kN\n",
    "    beta_mean = aN / bN\n",
    "    beta_var = (aN**2) / bN\n",
    "    \n",
    "    return mN, vN, beta_mean, beta_var\n",
    "\n",
    "def new_vb_solution(data, m0, v0, beta_mean0, beta_var0, iterations=10):\n",
    "    N = len(data)\n",
    "    s1 = np.sum(data)\n",
    "    s2 = np.sum(np.square(data))\n",
    "    xbar = np.mean(data)\n",
    "    a0, b0 = (beta_mean0**2)/beta_var0, (beta_mean0/beta_var0)\n",
    "    k0 = 1 / v0\n",
    "    mN = (k0*m0 + N*xbar) / (k0 + N)\n",
    "    aN = a0 + ((N + 1) / 2)\n",
    "    m, k, a, b = mN, k0, aN, b0\n",
    "    for i in range(iterations):\n",
    "        k = (k0 + N) * a / b\n",
    "        b = b0 + 0.5*((k0 + N) * ((1/k) + (m**2)) - 2*m*(k0*m0 + s1) + s2 + k0*(m0**2))\n",
    "    v = 1 / k\n",
    "    beta_mean = a / b\n",
    "    beta_var = (a**2) / b\n",
    "    return m, v, beta_mean, beta_var\n",
    "\n",
    "def get_contour(x, mean, std):\n",
    "    return (1 / (std * np.sqrt(np.pi))) * np.exp(-0.5 * np.square((x - mean) / std))\n",
    "\n",
    "def plot_contours(ax):\n",
    "    meanE, standard_devE = [], []\n",
    "    meanVB, standard_devVB = [], []\n",
    "    # average over 100 runs\n",
    "    for i in range(100):\n",
    "        data = np.random.normal(mu.value, std.value, [N.value])\n",
    "\n",
    "        # get exact and VB solutions\n",
    "        mE, vE, beta_meanE, beta_varE = new_exact_solution(w.value, m0.value, v0.value, beta_mean0.value, beta_var0.value)\n",
    "        mVB, vVB, beta_meanVB, beta_varVB = new_vb_solution(w.value, m0.value, v0.value, beta_mean0.value, beta_var0.value, 10)\n",
    "        stdE, stdVB = [1/np.sqrt(beta_mean) for beta_mean in (beta_meanE, beta_meanVB)]\n",
    "        \n",
    "        # append to list\n",
    "        meanE.append(mE)\n",
    "        standard_devE.append(stdE)\n",
    "        meanVB.append(mVB)\n",
    "        standard_devVB.append(stdVB)\n",
    "        \n",
    "    # take mean across all runs\n",
    "    mE, stdE = [np.mean(s) for s in (meanE, standard_devE)]\n",
    "    mVB, stdVB = [np.mean(s) for s in (meanVB, standard_devVB)]\n",
    "    \n",
    "    # get range of points on x-axis\n",
    "    x = np.linspace(mu.value-3*std.value, mu.value+3*std.value, 1000)\n",
    "    x = np.linspace(mE-3*stdE, mE+3*stdE, 1000)\n",
    "    \n",
    "    # get contours\n",
    "    yE = get_contour(x, mE, stdE)\n",
    "    yVB = get_contour(x, mVB, stdVB)\n",
    "    \n",
    "    # plot\n",
    "    ax.plot(x, yE, color='b', label='Exact solution')\n",
    "    ax.plot(x, yVB, color='b', ls='--', label='Approximate solution')\n",
    "    \n",
    "    ax.legend(loc='upper right')\n",
    "\n",
    "def update_contour_plot(change):\n",
    "    ax7.clear()\n",
    "    plot_contours(ax7)\n",
    "\n",
    "fig7, ax7 = plt.subplots(num=7)\n",
    "plot_contours(ax7)\n",
    "\n",
    "display(grid);\n",
    "\n",
    "[w.children[n].observe(update_contour_plot, 'value') for n in range(len(w.children))];\n",
    "[prior_widget.children[n].observe(update_contour_plot, 'value') for n in range(len(prior_widget.children))];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cb93945",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this cell has the MLaPP VB solution\n",
    "a0 = (beta_mean0.value**2) / beta_var0.value\n",
    "b0 = beta_mean0.value / beta_var0.value\n",
    "\n",
    "k0 = 1 / v0.value\n",
    "\n",
    "xbar = np.mean(w.value)\n",
    "\n",
    "mN = (k0*m0.value + N.value*xbar) / (k0 + N.value)\n",
    "aN = a0 + (N.value+1)/2\n",
    "\n",
    "# emu = mN\n",
    "\n",
    "# m, k, a, b = mN, k0, aN, b0\n",
    "# for i in range(10):\n",
    "#     k = (k0 + N.value) * a / b\n",
    "#     emusquare = (1/k) + (m**2)\n",
    "#     b = b0 + k0 * (emusquare + (m0.value**2) - 2*emu*m0.value) + 0.5 * np.sum(np.square(w.value) + emusquare - 2*emu*w.value)\n",
    "\n",
    "m, k, a, b = mN, k0, aN, b0\n",
    "s1 = np.sum(w.value)\n",
    "s2 = np.sum(np.square(w.value))\n",
    "for i in range(10):\n",
    "    k = (k0 + N.value) * a / b\n",
    "    b = b0 + 0.5 * ((k0 + N.value)*((1/k) + (m**2)) - 2 * m * (k0*m0.value + s1) + s2 + k0*(m0.value**2))\n",
    "\n",
    "# print(m, k, a, b)\n",
    "print(m, 1/k, a/b, (a**2)/b)\n",
    "gamma_mean = a / b\n",
    "print(f\"Gamma mean = {gamma_mean}\")\n",
    "standard_deviation = np.sqrt(1/gamma_mean)\n",
    "print(f\"Standard deviation = {standard_deviation}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
